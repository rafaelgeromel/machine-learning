{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting deeper with Keras\n",
    "\n",
    "Jay Urbain\n",
    "\n",
    "* Tensorflow is a powerful and flexible tool, but coding large neural architectures with it is tedious.\n",
    "* There are plenty of deep learning toolkits that work on top of it like Slim, TFLearn, Sonnet, Keras.\n",
    "* Choice is matter of taste and particular task\n",
    "* We'll be using Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.datasets import mnist\n",
    "\n",
    "mnist = keras.datasets.mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.imshow(X_train[0]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n",
      "(60000, 10)\n",
      "(10000, 28, 28, 1)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.reshape((60000, 28, 28, 1))\n",
    "X_train = X_train.astype('float32')/255\n",
    "\n",
    "X_test = X_test.reshape((10000, 28, 28, 1))\n",
    "X_test = X_test.astype('float32')/255\n",
    "\n",
    "num_classes = 10\n",
    "y_train = keras.utils.to_categorical(y_train)\n",
    "y_test = keras.utils.to_categorical(y_test)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "import keras.layers as ll\n",
    "\n",
    "model = Sequential(name=\"mlp\")\n",
    "\n",
    "model.add(ll.InputLayer([28, 28]))\n",
    "\n",
    "model.add(ll.Flatten())\n",
    "\n",
    "# network body\n",
    "model.add(ll.Dense(25))\n",
    "model.add(ll.Activation('linear'))\n",
    "\n",
    "model.add(ll.Dense(25))\n",
    "model.add(ll.Activation('linear'))\n",
    "\n",
    "# output layer: 10 neurons for each class with softmax\n",
    "model.add(ll.Dense(10, activation='softmax'))\n",
    "\n",
    "# categorical_crossentropy is your good old crossentropy\n",
    "# but applied for one-hot-encoded vectors\n",
    "model.compile(\"adam\", \"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_5 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 25)                19625     \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 25)                0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 25)                650       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 25)                0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 10)                260       \n",
      "=================================================================\n",
      "Total params: 20,535\n",
      "Trainable params: 20,535\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model interface\n",
    "\n",
    "Keras models follow __Scikit-learn__'s interface of fit/predict with some notable extensions. Let's take a tour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected input_5 to have 3 dimensions, but got array with shape (60000, 28, 28, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-40493952b8e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m history = model.fit(X_train, y_train.reshape(-1,1),\n\u001b[1;32m      7\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m           verbose=2)\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;31m#           validation_data=(X_test, y_test))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m    953\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    749\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    126\u001b[0m                         \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    129\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected input_5 to have 3 dimensions, but got array with shape (60000, 28, 28, 1)"
     ]
    }
   ],
   "source": [
    "# fit(X,y) ships with a neat automatic logging.\n",
    "#          Highly customizable under the hood.\n",
    "# model.fit(X_train, y_train,\n",
    "#           validation_data=(X_test, y_test), epochs=5);\n",
    "\n",
    "history = model.fit(X_train, y_train.reshape(-1,1),\n",
    "          batch_size=128, epochs=20,\n",
    "          verbose=2)\n",
    "#           validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  2.19691530e-04,   2.33067796e-02,   8.44826028e-02,\n",
       "          8.43768835e-01,   3.28484589e-06,   1.48870070e-02,\n",
       "          1.89019216e-03,   8.13943046e-09,   3.14378813e-02,\n",
       "          3.66758718e-06],\n",
       "       [  2.27790019e-06,   2.51845086e-05,   6.56424556e-03,\n",
       "          7.39667797e-03,   1.15967309e-03,   7.40212528e-03,\n",
       "          3.55782436e-06,   2.09837594e-06,   9.77138400e-01,\n",
       "          3.05777270e-04]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# estimate probabilities P(y|x)\n",
    "model.predict_proba(X_val[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save trained weights\n",
    "model.save(\"weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9312/10000 [==========================>...] - ETA: 0s\n",
      "Loss, Accuracy =  [0.28471082768142225, 0.9194]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nLoss, Accuracy = \", model.evaluate(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Whoops!\n",
    "So far our model is staggeringly inefficient. There is something wring with it. Guess, what?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### My Keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "import keras.layers as ll\n",
    "from keras import regularizers\n",
    "from keras import optimizers\n",
    "\n",
    "model = Sequential(name=\"mlp\")\n",
    "\n",
    "model.add(ll.InputLayer([28, 28]))\n",
    "\n",
    "model.add(ll.Flatten())\n",
    "\n",
    "# network body\n",
    "# model.add(ll.Dense(100, activation='relu', kernel_regularizer=regularizers.l2(0.001), activity_regularizer=regularizers.l1(0.001) ))\n",
    "model.add(ll.Dense(100, activation='relu'))\n",
    "model.add(ll.Dropout(0.3, noise_shape=None, seed=None))\n",
    "#model.add(ll.Dense(100, activation='relu', kernel_regularizer=regularizers.l2(0.001), activity_regularizer=regularizers.l1(0.001) ))\n",
    "model.add(ll.Dense(100, activation='relu'))\n",
    "model.add(ll.Dropout(0.3, noise_shape=None, seed=None))\n",
    "\n",
    "# output layer: 10 neurons for each class with softmax\n",
    "model.add(ll.Dense(10, activation='softmax'))\n",
    "\n",
    "# categorical_crossentropy is your good old crossentropy\n",
    "# but applied for one-hot-encoded vectors\n",
    "\n",
    "# opt = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0)\n",
    "\n",
    "model.compile(\"adam\", \"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_12 (InputLayer)        (None, 28, 28)            0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 89,610\n",
      "Trainable params: 89,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras + tensorboard\n",
    "\n",
    "Remember the interactive graphs from Tensorboard one notebook ago? \n",
    "\n",
    "Thing is, Keras can use tensorboard to show you a lot of useful information about the learning progress. Just take a look!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm -r /tmp/tboard/**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 8s - loss: 0.4199 - acc: 0.8711 - val_loss: 0.1394 - val_acc: 0.9585\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 8s - loss: 0.2123 - acc: 0.9363 - val_loss: 0.1156 - val_acc: 0.9675\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 8s - loss: 0.1698 - acc: 0.9500 - val_loss: 0.0958 - val_acc: 0.9730\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 8s - loss: 0.1492 - acc: 0.9548 - val_loss: 0.0940 - val_acc: 0.9746\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 8s - loss: 0.1357 - acc: 0.9582 - val_loss: 0.0878 - val_acc: 0.9743\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 7s - loss: 0.1248 - acc: 0.9617 - val_loss: 0.0955 - val_acc: 0.9739\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 7s - loss: 0.1167 - acc: 0.9646 - val_loss: 0.0834 - val_acc: 0.9761\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 8s - loss: 0.1094 - acc: 0.9660 - val_loss: 0.0813 - val_acc: 0.9777\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 8s - loss: 0.1033 - acc: 0.9678 - val_loss: 0.0814 - val_acc: 0.9771\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 8s - loss: 0.0978 - acc: 0.9692 - val_loss: 0.0797 - val_acc: 0.9782\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 8s - loss: 0.0950 - acc: 0.9695 - val_loss: 0.0794 - val_acc: 0.9783\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 8s - loss: 0.0893 - acc: 0.9720 - val_loss: 0.0835 - val_acc: 0.9787\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 8s - loss: 0.0869 - acc: 0.9728 - val_loss: 0.0857 - val_acc: 0.9762\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 8s - loss: 0.0864 - acc: 0.9729 - val_loss: 0.0792 - val_acc: 0.9785\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 8s - loss: 0.0838 - acc: 0.9740 - val_loss: 0.0786 - val_acc: 0.9790\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 8s - loss: 0.0808 - acc: 0.9744 - val_loss: 0.0830 - val_acc: 0.9770\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 7s - loss: 0.0794 - acc: 0.9751 - val_loss: 0.0842 - val_acc: 0.9788\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 7s - loss: 0.0805 - acc: 0.9746 - val_loss: 0.0764 - val_acc: 0.9797\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 8s - loss: 0.0753 - acc: 0.9756 - val_loss: 0.0808 - val_acc: 0.9781\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 8s - loss: 0.0747 - acc: 0.9762 - val_loss: 0.0875 - val_acc: 0.9783\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 8s - loss: 0.0710 - acc: 0.9776 - val_loss: 0.0814 - val_acc: 0.9800\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 7s - loss: 0.0709 - acc: 0.9776 - val_loss: 0.0853 - val_acc: 0.9792\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 7s - loss: 0.0732 - acc: 0.9769 - val_loss: 0.0830 - val_acc: 0.9788\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 7s - loss: 0.0658 - acc: 0.9789 - val_loss: 0.0761 - val_acc: 0.9800\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 8s - loss: 0.0687 - acc: 0.9787 - val_loss: 0.0825 - val_acc: 0.9786\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 8s - loss: 0.0689 - acc: 0.9783 - val_loss: 0.0772 - val_acc: 0.9820\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 8s - loss: 0.0623 - acc: 0.9805 - val_loss: 0.0819 - val_acc: 0.9795\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 8s - loss: 0.0669 - acc: 0.9784 - val_loss: 0.0803 - val_acc: 0.9799\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 8s - loss: 0.0629 - acc: 0.9802 - val_loss: 0.0842 - val_acc: 0.9809\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 8s - loss: 0.0614 - acc: 0.9807 - val_loss: 0.0839 - val_acc: 0.9803\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 8s - loss: 0.0628 - acc: 0.9799 - val_loss: 0.0862 - val_acc: 0.9782\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 8s - loss: 0.0616 - acc: 0.9798 - val_loss: 0.0797 - val_acc: 0.9793\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 8s - loss: 0.0623 - acc: 0.9806 - val_loss: 0.0787 - val_acc: 0.9796\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 8s - loss: 0.0605 - acc: 0.9809 - val_loss: 0.0795 - val_acc: 0.9820\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 8s - loss: 0.0586 - acc: 0.9813 - val_loss: 0.0811 - val_acc: 0.9798\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 8s - loss: 0.0583 - acc: 0.9817 - val_loss: 0.0908 - val_acc: 0.9783\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 8s - loss: 0.0595 - acc: 0.9813 - val_loss: 0.0845 - val_acc: 0.9806\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 8s - loss: 0.0598 - acc: 0.9811 - val_loss: 0.0867 - val_acc: 0.9790\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 8s - loss: 0.0578 - acc: 0.9815 - val_loss: 0.0855 - val_acc: 0.9786\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 8s - loss: 0.0546 - acc: 0.9826 - val_loss: 0.0830 - val_acc: 0.9799\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 8s - loss: 0.0570 - acc: 0.9831 - val_loss: 0.0918 - val_acc: 0.9778\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 8s - loss: 0.0563 - acc: 0.9814 - val_loss: 0.0861 - val_acc: 0.9810\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 8s - loss: 0.0542 - acc: 0.9823 - val_loss: 0.0892 - val_acc: 0.9783\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 8s - loss: 0.0556 - acc: 0.9825 - val_loss: 0.0900 - val_acc: 0.9795\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 8s - loss: 0.0514 - acc: 0.9834 - val_loss: 0.0899 - val_acc: 0.9803\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 8s - loss: 0.0525 - acc: 0.9831 - val_loss: 0.0917 - val_acc: 0.9786\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 8s - loss: 0.0526 - acc: 0.9834 - val_loss: 0.0902 - val_acc: 0.9788\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 7s - loss: 0.0531 - acc: 0.9834 - val_loss: 0.0912 - val_acc: 0.9794\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 8s - loss: 0.0532 - acc: 0.9836 - val_loss: 0.0865 - val_acc: 0.9786\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 7s - loss: 0.0506 - acc: 0.9835 - val_loss: 0.0911 - val_acc: 0.9797\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import TensorBoard\n",
    "num_epochs = 50\n",
    "history = model.fit(X_train, y_train, validation_data=(X_val, y_val), \n",
    "          epochs=num_epochs,\n",
    "          callbacks=[TensorBoard(\"/tmp/tboard\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEWCAYAAAB1xKBvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGGNMSP4/ybL9LbUTtyUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbc31c82ac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['acc']\n",
    "print(len(acc))\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# \"bo\" is for \"blue dot\"\n",
    "plt.plot(epochs, loss, 'y', label='Training loss')\n",
    "# b is for \"solid blue line\"\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9472/10000 [===========================>..] - ETA: 0s\n",
      "Test accuracy: 97.72999999999999 %\n",
      "Great job!\n"
     ]
    }
   ],
   "source": [
    "# Test score...\n",
    "test_predictions = model.predict_proba(X_test).argmax(axis=-1)\n",
    "test_answers = y_test.argmax(axis=-1)\n",
    "\n",
    "test_accuracy = np.mean(test_predictions==test_answers)\n",
    "\n",
    "print(\"\\nTest accuracy: {} %\".format(test_accuracy*100))\n",
    "\n",
    "assert test_accuracy>=0.92,\"Logistic regression can do better!\"\n",
    "assert test_accuracy>=0.975,\"Your network can do better!\"\n",
    "print(\"Great job!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "answer_submitter = grading.Grader(\"0ybD9ZxxEeea8A6GzH-6CA\")\n",
    "answer_submitter.set_answer(\"N56DR\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted to Coursera platform. See results on assignment page!\n"
     ]
    }
   ],
   "source": [
    "answer_submitter.submit('jay.urbain@gmail.com', 'UC8V2hBDKDl4tPKn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tips & tricks\n",
    "\n",
    "Here are some tips on what you could do. Don't worry, to reach the passing threshold you don't need to try all the ideas listed here, feel free to stop once you reach the 0.975 accuracy mark.\n",
    "\n",
    " * __Network size__\n",
    "   * More neurons, \n",
    "   * More layers, ([docs](https://keras.io/))\n",
    "\n",
    "   * Nonlinearities in the hidden layers\n",
    "     * tanh, relu, leaky relu, etc\n",
    "   * Larger networks may take more epochs to train, so don't discard your net just because it could didn't beat the baseline in 5 epochs.\n",
    "\n",
    "\n",
    " * __Early Stopping__\n",
    "   * Training for 100 epochs regardless of anything is probably a bad idea.\n",
    "   * Some networks converge over 5 epochs, others - over 500.\n",
    "   * Way to go: stop when validation score is 10 iterations past maximum\n",
    "     \n",
    "\n",
    " * __Faster optimization__\n",
    "   * rmsprop, nesterov_momentum, adam, adagrad and so on.\n",
    "     * Converge faster and sometimes reach better optima\n",
    "     * It might make sense to tweak learning rate/momentum, other learning parameters, batch size and number of epochs\n",
    "\n",
    "\n",
    " * __Regularize__ to prevent overfitting\n",
    "   * Add some L2 weight norm to the loss function, theano will do the rest\n",
    "     * Can be done manually or via - https://keras.io/regularizers/\n",
    "   \n",
    "   \n",
    " * __Data augmemntation__ - getting 5x as large dataset for free is a great deal\n",
    "   * https://keras.io/preprocessing/image/\n",
    "   * Zoom-in+slice = move\n",
    "   * Rotate+zoom(to remove black stripes)\n",
    "   * any other perturbations\n",
    "   * Simple way to do that (if you have PIL/Image): \n",
    "     * ```from scipy.misc import imrotate,imresize```\n",
    "     * and a few slicing\n",
    "   * Stay realistic. There's usually no point in flipping dogs upside down as that is not the way you usually see them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 28, 28)            0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 25)                19625     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 25)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 25)                650       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 25)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                260       \n",
      "=================================================================\n",
      "Total params: 20,535\n",
      "Trainable params: 20,535\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf)",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "120px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
