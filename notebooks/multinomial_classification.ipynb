{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial (Multi-class) Classification with MNIST and Logistic Regression\n",
    "\n",
    "Jay Urbain, PhD\n",
    "\n",
    "References:\n",
    "\n",
    "- Games, G., Witten, D., Hastie, T., and Tibshirani, R. (2013) An Introduction to Statistical Learning\n",
    "with applications in R, www.StatLearning.com, Springer-Verlag, New York. Chapter 4.\n",
    "\n",
    "- [scikit-learn](http://scikit-learn.org/stable/)\n",
    "\n",
    "In this notebook we will be applying multinomial logistic regression classification using *scikit-learn* to classify instances of digits using the  *MNIST* dataset.\n",
    "\n",
    "You will be guided through fitting and evaluating a multinomial Logistic Regression classifier to the MNIST dataset.\n",
    "\n",
    "Complete the **TODO** items in the cell(s) below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To support both python 2 and python 3\n",
    "#from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# plotting\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the MNIST dataset using scikit-learn fetch_mldata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_mldata\n",
    "mnist = fetch_mldata('MNIST original')\n",
    "mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*fetch_mldata* uses `utils.Bunch` to encapsulate datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(mnist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 70,000 images (28 by 28 images for a dimensionality of 784) and 70,000 labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(mnist.data.shape)\n",
    "\n",
    "# These are the labels\n",
    "print(mnist.target.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting Data into Training and Test Sets (MNIST)\n",
    "\n",
    "The code below splits the data into training and test data sets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO:** Split the data into 70% train, and 30% test samples uising `sklearn.model_selection.train_test_split.` Use `random_state=0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your work here:\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_img, test_img, train_lbl, test_lbl = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Showing MNIST Images and Labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(20,4))\n",
    "for index, (image, label) in enumerate(zip(train_img[0:5], train_lbl[0:5])):\n",
    " plt.subplot(1, 5, index + 1)\n",
    " plt.imshow(np.reshape(image, (28,28)), cmap=plt.cm.gray)\n",
    " plt.title('Training: %i\\n' % label, fontsize = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting a classification model to the data.\n",
    "\n",
    "#### Step 1: Import the logistic regression classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2. Make an instance of the Model\n",
    "\n",
    "**TODO:** Instantiate your logic regression model.\n",
    "\n",
    "All parameters not specified are set to their defaults. The  default solver `liblinear` is relatively slow. Change the solver to `lbfgs` when you instanciate your model. Please feel free to experiment with other solvers.\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your work here\n",
    "\n",
    "logisticRegression = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3. Train the model on the training data \n",
    "\n",
    "Training is all about learning the relationships between the predictor variables and target variable.\n",
    "\n",
    "\n",
    "**TODO:** Fit your model to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your work here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obtain Step 4. \n",
    "\n",
    "**TODO:** Predict labels on hold out data. As a sanity test, first predict labels on the first ten test images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your work here\n",
    "# Note: predict returns a NumPy Array\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO:** Predict labels on the entire set of test images. Assign the results to `predictions.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns a NumPy Array\n",
    "# Predict for One Observation (image)\n",
    "predictions = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Measuring Model Performance\n",
    "\n",
    "While there are other ways of measuring model performance (precision, recall, F1 Score, ROC Curve, etc). First, lets use accuracy as our metric. \n",
    "\n",
    "$Accuracy = \\dfrac{correct \\space predictions}{total \\space predictions}$\n",
    "\n",
    "**TODO:** Use the LogisticRegression `score()` method to retrieve and display the model accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your work here\n",
    "\n",
    "score = \n",
    "print(score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate incorrect classifications\n",
    "\n",
    "A confusion matrix is a table that is often used to describe the performance of a classification model (or “classifier”) on a set of test data for which the true values are known. \n",
    "\n",
    "Each entry  in a confusion matrix *(i, j)* is the number of observations actually in group *i* but predicted to be in group *j* (column).\n",
    "\n",
    "Note: Wikipedia and other references may use different convention for axes:   \n",
    "https://en.wikipedia.org/wiki/Confusion_matrix    \n",
    "\n",
    "A confusion matrix can be generated using scikit-learn.   \n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = metrics.confusion_matrix(test_lbl, predictions)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the confusion matrix can make interpreting the results more clear.\n",
    "\n",
    "Here is the confusion matrix plotted in matplotlib. Its a bit involved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,9))\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title('Confusion matrix', size = 15)\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(10)\n",
    "plt.xticks(tick_marks, [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"], rotation=45, size = 10)\n",
    "plt.yticks(tick_marks, [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"], size = 10)\n",
    "plt.tight_layout()\n",
    "plt.ylabel('Actual label', size = 15)\n",
    "plt.xlabel('Predicted label', size = 15)\n",
    "width, height = cm.shape\n",
    "for x in range(width):\n",
    "    for y in range(height):\n",
    "        plt.annotate(str(cm[x][y]), xy=(y, x), \n",
    "        horizontalalignment='center',\n",
    "        verticalalignment='center')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the confusion matrix with Seaborn is a bit easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,9))\n",
    "sns.heatmap(cm, annot=True, fmt=\".2f\", linewidths=.5, square = True, cmap = 'Blues_r');\n",
    "plt.ylabel('Actual label');\n",
    "plt.xlabel('Predicted label');\n",
    "all_sample_title = 'Accuracy Score: {0}'.format(score)\n",
    "plt.title(all_sample_title, size = 15);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Displaying misclassified images with predicted labels  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "index = 0\n",
    "misclassifiedIndexes = []\n",
    "for label, predict in zip(test_lbl, predictions):\n",
    "    if label != predict: \n",
    "#         print(label, predict)\n",
    "        misclassifiedIndexes.append(index)\n",
    "    index +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Showing the misclassified images and image labels using matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,4))\n",
    "for plotIndex, badIndex in enumerate(misclassifiedIndexes[0:5]):\n",
    "#     print(plotIndex, badIndex)\n",
    "    plt.subplot(1, 5, plotIndex + 1)\n",
    "    plt.imshow(np.reshape(test_img[badIndex], (28,28)), cmap=plt.cm.gray)\n",
    "    plt.title('Predicted: {}, Actual: {}'.format(predictions[badIndex], test_lbl[badIndex]), fontsize = 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO:** Qualitatively, i.e., by observation, try to identify types of missclassifications, i.e., mixing up `5` with `6`, by reviewing missclassified images (see above).\n",
    "    \n",
    "Observations:\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Terminology\n",
    "\n",
    "For each class label, e.g., 0, 1, ..., 9:\n",
    "- true positive (TP) - correctly classified as positive example   \n",
    "- true negative (TN) - correctly classified as negative example\n",
    "- false positive (FP)- incorrectly classified as positive example  \n",
    "- false negative (FN)- incorrectly classified as negative example  \n",
    "\n",
    "Accuracy = TP+TN/ALL\n",
    "\n",
    "We will discuss these measurements in more detail in class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO:** Try to quantitatively identify missclassifications and types of missclassifications using confusion matrix data (above).\n",
    "    \n",
    "For example, what is the accuracy of each number? For each number what numbers is it typically confused by?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your work here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BONUS:** Evaluate one or more other scikit-learn classifiers on the MNIST dataset and try to top your screo with logistic regession.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional work here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
