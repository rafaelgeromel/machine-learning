{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Learning: Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning\n",
    "\n",
    "Jay Urbain, PhD\n",
    "\n",
    "References:\n",
    "\n",
    "- James, G., Witten, D., Hastie, T., and Tibshirani, R. (2013) An Introduction to Statistical Learning, with applications in R, www.StatLearning.com, Springer-Verlag, New York. Chapter 4.\n",
    "\n",
    "- [scikit-learn](http://scikit-learn.org/stable/) \n",
    "\n",
    "In this notebook we will be working through a *linear regression* application using *scikit-learn*. \n",
    "\n",
    "Answer **questions** in the empty cell(s) below each question in the notebook. Here are the steps we will follow. Also summarize your answers to each question in your lab report.\n",
    "\n",
    "\n",
    "1: Importing the data.\n",
    "\n",
    "2: Visualizing the data.\n",
    "\n",
    "3: Review Ordinary Least Squares (OLS) regression.\n",
    "\n",
    "4: Use Numpy for univariate linear regression.\n",
    "\n",
    "5: Determing the error of our model fit.\n",
    "\n",
    "6: Use *scikit-learn* to implement multivariate regression.\n",
    "\n",
    "7: Use training and validation data sets.  \n",
    "\n",
    "8: Predicting prices\n",
    "\n",
    "9: Generating residual plots\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1: Importing the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the Numpy and Pandas libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Searborn statistical](https://stanford.edu/~mwaskom/software/seaborn/) visualization library installation\n",
    "\n",
    "Use the conda package to install the seaborn library from a terminal window as follows:\n",
    "\n",
    "conda install seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import plotting packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "# plots within notebook versus launching a separate window\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the Boston housing dataset.\n",
    "\n",
    "*Notes: \n",
    "- You may have to run a separate download, scikit learn will read an error and prompt you if you don't have the datasets.\n",
    "- Notice the type of the Boston data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the Boston dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = load_boston()\n",
    "print ('Dataset: ', type(boston))\n",
    "# the actual data is in a numpy array\n",
    "print ('Data: ', type(boston.data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The built-in datasets have meta-data included that describe the data. This is not the case with most datasets. Typically you'll have to dig around for information. You'll also have to spend considerably more time cleaning and normlizing the data.\n",
    "\n",
    "You can access the meta-data via the DESCR field:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( boston.DESCR )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2: Visualize the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Its *always* a good idea to visualize your data. \n",
    "\n",
    "We can use matplotlib.pyplot to generate a histogram. In the built-in datasets, the target field represents the column in the numpy multi-dimensional array (matrix) that is the *target* variable, i.e., what we are trying to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of prices (this is the target of our dataset)\n",
    "plt.hist(boston.target, bins=50)\n",
    "\n",
    "#label\n",
    "plt.xlabel('Price in $1000s')\n",
    "plt.ylabel('Number of houses')\n",
    "plt.title('Figure 1. Price Histogram')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scatter plot of prices\n",
    "\n",
    "We can use a scatter plot of prices versus the number of rooms in the dwelling, or prices versus any other predictor to explore the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the column at the 5 index (Labeled RM)\n",
    "plt.scatter(boston.data[:,5], boston.target)\n",
    "\n",
    "#label\n",
    "plt.ylabel('Price in $1000s')\n",
    "plt.xlabel('Number of rooms')\n",
    "print('Figure 2. Price versus Number of Rooms Scatter Plot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see a trend showing that in general, price increases with an increasing number of rooms in the house. Makes sense."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1) There's an anomolly in the price target variable in the Boston dataset. What is it? See figures 1 and 2 above. Answer in the cell below.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We can use the Seaborn statistical visulization package to plot a linear regression model on the scatter plot to visualize how well a linear regression model fits the data. Seaborn requires that the data be in a pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load the data into a pandas DataFrame\n",
    "boston_df = DataFrame(boston.data)\n",
    "\n",
    "# add label columns to the dataframe from the original dataset\n",
    "boston_df.columns = boston.feature_names\n",
    "\n",
    "#show\n",
    "boston_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the target variable, price, i.e., the variable we are tring to predict in the Boston data set. \n",
    "\n",
    "Create a new price column in the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set price column for target\n",
    "boston_df['Price'] = boston.target"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Verify the prediction column has been added correctly to the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show result\n",
    "boston_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Seaborn lmplot() function, fits a linear regression model to the data, plots the data as a scater plot, and adds the regression line. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use seabron to create and plot a linear fit\n",
    "sns.lmplot('RM','Price',data = boston_df)\n",
    "print ('Figure 3. Linear Model Regression Plot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note: The transluscent bands correspond to the confidence interval. The default is ci=95% confidence interval*\n",
    "https://web.stanford.edu/~mwaskom/software/seaborn/generated/seaborn.lmplot.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3: Ordinary Least Squares (OLS) Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OLS regression fits a linear model (line in univariate regression, plane with two variates) by minimizing the residual sum of squares. Residuals are shown as red lines in the plot below. The residuals represent the difference between the predicted (point on line) and actual data (point). *Note: the plot below was generated from a different dataset using R. It is for illustrative purposes.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot of linear regression residuals\n",
    "from IPython.display import Image\n",
    "print( 'Figure 4. Linear regression residuals' )\n",
    "Image('linear_regression_residuals.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best fit is defined as the line that minimizes the residual sum of squares:\n",
    "\n",
    "$RSS=\\sum_{i}^{m}(\\hat{y}_i - {y}_i)^2$\n",
    "\n",
    "Where $\\hat{y}=\\beta_0 + \\beta_1x$\n",
    "\n",
    "The least-square line approximating the set of points:\n",
    "\n",
    "$ (x,y)_{1},(x,y)_{2},(x,y)_{3},...,(x,y)_{m}$\n",
    "\n",
    "has the equation: $ \\hat{Y} = \\beta_{0} +\\beta_{1}X $\n",
    "\n",
    "I.e., the equation of a line: $Y=mx+b$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can solve for our coefficients using gradient descent (see lab 2) or the normal equation (see class materials)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4: Using Numpy for a Univariate Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy has a OLS method in its linear algebra library. We'll use this for our univariate regression. We will move on to scikit-learn for Multivariate regression.\n",
    "\n",
    "Numpy expects a *2D* array. The first dimension contains the different values. The second dimension contains the attribute number. In this case, the value is the mean number of rooms per house. Since this is a single attribute, the second dimension of the array is 1. So we need to create a (506,1) shape array. We can use numpy's vertical stack tool, *vstack*, to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up X as the room median values\n",
    "X = boston_df.RM\n",
    "print( X[1:5])\n",
    "\n",
    "# Use vstack to make X two-dimensional\n",
    "X = np.vstack(boston_df.RM)\n",
    "print( X[1:5])\n",
    "\n",
    "# Set up Y as the house target price.\n",
    "Y = boston_df.Price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The linear regression model: $Y=mX+b$\n",
    "\n",
    "can be represented in matrix form: $Y=A\\beta$\n",
    "\n",
    "where: $A = \\begin{bmatrix}x & 1\\end{bmatrix}$\n",
    "\n",
    "and $\\beta = \\begin{bmatrix}m \\\\b\\end{bmatrix}$\n",
    "\n",
    "We can calculate the $A$ matrix using numpy. We can do this by creating a matrix in the form $[X 1]$,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the X array in the form [X 1]\n",
    "X = np.array( [ [value,1] for value in X ] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can get the best fit values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now calculate our coefficients for the best fit line\n",
    "m, b = np.linalg.lstsq(X, Y)[0]\n",
    "np.linalg.lstsq(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot the data using the original data format of the Boston housing information. We performed the matrix transformations to utilize the numpy least square method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot points, Price vs Mean Number of Rooms\n",
    "plt.plot(boston_df.RM,boston_df.Price,'o')\n",
    "\n",
    "# Plot best fit line\n",
    "x= boston_df.RM\n",
    "plt.plot(x, m*x + b,'r',label='Best Fit Line')\n",
    "print ('Figure. 5, Price vs. Mean Number of Rooms')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5: Getting the error "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2) Calculate the RSS (as defined in step 3) for the univariate linear regression model of the Boston dataset created in step 4.** Use the cell below.\n",
    "\n",
    "$RSS=\\sum_{i}^{m}(\\hat{y}_i - {y}_i)^2$\n",
    "\n",
    "Where $\\hat{y}=\\beta_0 + \\beta_1x$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can calculate the [root mean square error](http://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.lstsq.html) of our fitted regression line.\n",
    "\n",
    "The result array has the residual squared error (RSS). For each element, it checks the the difference between the line (our prediction) and the true value, squares it, and returns the sum of all these. This is the RSS value.\n",
    "\n",
    "The root mean squared error is similar to the standard deviation. To find the root mean square error we divide by the number of elements and then take the square root. \n",
    "\n",
    "$RMSE=\\sqrt{\\dfrac{RSS}{N}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q3) Calculate the RMSE.** Use the cell below.\n",
    "\n",
    "Note: numpy has a linear algebra package containing a function for calculating the \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the root mean square error (RMSE) corresponds to the standard deviation, we can say that the price of a house will not vary by more than 2 times the RMSE 95% of the time. \n",
    "\n",
    "**Q4. How much will the price of a house vary 95% of the time?** Use the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q5) Calculate the TSS for the univariate linear regression model of the Boston dataset.** Use the cell below.\n",
    "\n",
    "$TSS=\\sum_{i}^{m}({y}_i - \\bar{y})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use vstack to make X two-dimensional\n",
    "X = boston_df.RM\n",
    "\n",
    "# Set up Y as the house target price.\n",
    "Y = boston_df.Price\n",
    "\n",
    "# your work here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q6) Calcualte $R^2$ for the univariate linear regression model of the Boston dataset.** Use the cell below.\n",
    "\n",
    "$R^2=\\dfrac{TSS - RSS}{TSS} = 1 - \\dfrac{RSS}{TSS}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6: Scikit-learn for multivariate regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Scikit-learn* can be used for univariate or multivariate regression.\n",
    "\n",
    "The [sklearn.linear_model.LinearRegression](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) class is called an estimator. \n",
    "\n",
    "Estimators predict a value based on the observed data. In scikit-learn, all estimators implement the *fit()* and *predict()* methods. The *fit()* method is used to learn the parameters of a model, and the *predict()* method is used to predict the value of a response variable for a given predictor variable using the learned coefficients. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Linear Regression\n",
    "import sklearn\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a LinearRegression object.\n",
    "\n",
    "*Note: After typing in an object, you can press tab to see a list of methods*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a LinearRegression Object\n",
    "lreg = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LinearRegression functions:\n",
    "\n",
    "- lreg.fit(): fits a linear model\n",
    "\n",
    "- lreg.predict(): predict Y from X using the linear regression model coefficients\n",
    "\n",
    "- lreg.score(): returns $R^2$, the [coefficient of determination](http://en.wikipedia.org/wiki/Coefficient_of_determination)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate the Boston dataframe into data columns and the target column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Columns\n",
    "X_multi = boston_df.drop('Price',1)\n",
    "\n",
    "# Targets\n",
    "Y_target = boston_df.Price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the linear regression model to X & Y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement Linear Regression\n",
    "lreg.fit(X_multi,Y_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Check the intercept and the number of coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(' The estimated intercept coefficient is %.2f ' %lreg.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(' The number of coefficients used was %d ' % len(lreg.coef_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Documentation](http://scikit-learn.org/stable/modules/linear_model.html).\n",
    "\n",
    "$ y(\\beta,x) = \\beta_0 + \\beta_1 x_1 + ... + \\beta_p x_p $\n",
    "\n",
    "Where $\\beta = (\\beta_1, ...\\beta_p)$ are the coefficients and $ \\beta_0 $ as the intercept."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Create a DataFrame to examine the model and the estimated coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame from the Features\n",
    "coeff_df = DataFrame(boston_df.columns)\n",
    "coeff_df.columns = ['Features']\n",
    "\n",
    "# Add a new column with the coefficients from the linear regression\n",
    "coeff_df[\"Coefficient Estimate\"] = pd.Series(lreg.coef_)\n",
    "\n",
    "# Show\n",
    "print ('Table 1. Multivariate coefficients')\n",
    "coeff_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q7) Which coefficients, excluding nitric oxide (NOX) have the strongest correlation with the target variable>** Use the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7: Using Training and Validation Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate training and test sets should be used to train and validate the model respectively.\n",
    "\n",
    "Samples for each set should be randomly selected.\n",
    "\n",
    "Fortunately, scikit-learn has a built in function specifically for this called train_test_split.\n",
    "\n",
    "The Scikit-learn [validation](http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.train_test_split.html) library has a function for this purpose. Below, we are creating separate training and tests sets, holding out 40% of the data for testing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = sklearn.model_selection.train_test_split(X,boston_df.Price, test_size=0.4, random_state=0)\n",
    "\n",
    "\n",
    "print (X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the results of the data split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print shapes of the training and testing data sets\n",
    "print (X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)\n",
    "\n",
    "# numpy expects matrix with dimension column\n",
    "X_train = X_train.values.reshape(X_train.shape[0],1)\n",
    "Y_train = Y_train.values.reshape(Y_train.shape[0],1)\n",
    "X_test = X_test.values.reshape(X_test.shape[0],1)\n",
    "Y_test = Y_test.values.reshape(Y_test.shape[0],1)\n",
    "\n",
    "print (X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8: Predicting Prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use our training set to build the model, and the test set to evaluate the performance of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression object\n",
    "lreg = LinearRegression()\n",
    "\n",
    "# Build a linear regression model on the training data only\n",
    "lreg.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform prediction on both the training set and the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on training and testing sets\n",
    "pred_train = lreg.predict(X_train)\n",
    "pred_test = lreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the mean square error for each:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Fit a model X_train, and calculate MSE with Y_train: %.2f\"  % np.mean((Y_train - pred_train) ** 2) )\n",
    "    \n",
    "print (\"Fit a model X_train, and calculate MSE with X_test and Y_test: %.2f\"  % np.mean((Y_test - pred_test) ** 2) )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 9 : Residual Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A residual plot is a graph that shows the residuals on the vertical axis and the independent variable (x) on the horizontal axis. If the points in a residual plot are randomly dispersed around the horizontal axis, a linear regression model is appropriate for the data; otherwise, a non-linear model is more appropriate.\n",
    "\n",
    "Residual plots are a good way to visualize the errors in your data.  A good model fit will show data points randomly and evenly scattered around line zero. If there is some strucutre or pattern, that means your model is not capturing some aspect of the data. There could be an interaction between predictor variables that we are not considering, or the data may be inherently non-linear. \n",
    "\n",
    "[Residual plots](http://blog.minitab.com/blog/adventures-in-statistics/why-you-need-to-check-your-residual-plots-for-regression-analysis)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot the training data\n",
    "train = plt.scatter(pred_train,(pred_train-Y_train),c='b',alpha=0.5)\n",
    "\n",
    "# Scatter plot the testing data\n",
    "test = plt.scatter(pred_test,(pred_test-Y_test),c='r',alpha=0.5)\n",
    "\n",
    "# Plot a horizontal axis line at 0\n",
    "plt.hlines(y=0,xmin=-10,xmax=50)\n",
    "\n",
    "#Labels\n",
    "plt.legend((train,test),('Training','Test'),loc='lower left')\n",
    "plt.title('Residual Plots')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like there aren't any major patterns to be concerned about, it may be interesting to check out the line occuring towards the bottom right, but overall the majority of the residuals seem to be randomly distributed above and below the horizontal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear regression is a broad topic with many applications. More information can be found in the scikit-lear documentation:  http://scikit-learn.org/stable/modules/linear_model.html#linear-model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q8) Review Table 1. Multivariate coefficients. Think about the meaning of a linear regression model, i.e., the \n",
    "coefficient reflects the change in the target variable for a one unit change in an input variable, with all other \n",
    "variables held constant. Identify a subset of features and build a model with these features. See if you can reduce \n",
    "RMSE and increase $R^2$.** \n",
    "\n",
    "Document your results in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
