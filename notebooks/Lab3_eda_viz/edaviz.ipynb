{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  EDA and visualization\n",
    "\n",
    "Jay Urbain, PhD\n",
    "\n",
    "In the last assignment we focussed on getting data into a tabular form and performing data-focused Exploratory Data Analysis. In this assignment, we will focus on the visualization part of Exploratory Data Analysis. \n",
    "\n",
    "References:  \n",
    "https://matplotlib.org/users/index.html   \n",
    "https://github.com/cs109  \n",
    "Python Data Science Handbook, Jake VanderPlas, 2017.    \n",
    "The Visual Display of Quantitative Information, 2001.  \n",
    "Python for Data Analysis: Data Wrangling with Pandas, NumPy, and IPython, 2017.\n",
    "Applied Multivariate Statistical Analysis, 2015.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The %... is an iPython magic command, and is not part of the Python language.\n",
    "# In this case we're telling the plotting library to draw things in\n",
    "# the notebook instead of in a separate window.\n",
    "%matplotlib inline \n",
    "\n",
    "import numpy as np # imports a fast numerical programming library\n",
    "import scipy as sp # imports stats functions, amongst other things\n",
    "import matplotlib as mpl # this actually imports matplotlib\n",
    "import matplotlib.cm as cm # allows us easy access to colormaps\n",
    "import matplotlib.pyplot as plt # sets up plotting under plt\n",
    "import pandas as pd # lets us handle data as dataframes\n",
    "\n",
    "#sets up pandas table display\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.notebook_repr_html', True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The seaborn API is changing, and `seaborn.apionly` is being deprecated. The default will soon behave like `apionly` and not change the standard matplotlib color scheme and defaults. Here we choose `apionly` to make sure we have to do everything explicitly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# versions below 0.8.1\n",
    "import seaborn.apionly as sns #sets up styles and gives us more plotting options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the mtcars dataset into shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "\n",
    "The documentation for this data is [here](https://stat.ethz.ch/R-manual/R-devel/library/datasets/html/mtcars.html) but I have extracted some relevant parts below:\n",
    "\n",
    "```\n",
    "Description\n",
    "\n",
    "The data was extracted from the 1974 Motor Trend US magazine, and comprises fuel consumption and 10 aspects of automobile design and performance for 32 automobiles (1973–74 models).\n",
    "\n",
    "Usage\n",
    "\n",
    "mtcars\n",
    "Format\n",
    "\n",
    "A data frame with 32 observations on 11 variables.\n",
    "\n",
    "[, 1]\tmpg\tMiles/(US) gallon\n",
    "[, 2]\tcyl\tNumber of cylinders\n",
    "[, 3]\tdisp\tDisplacement (cu.in.)\n",
    "[, 4]\thp\tGross horsepower\n",
    "[, 5]\tdrat\tRear axle ratio\n",
    "[, 6]\twt\tWeight (1000 lbs)\n",
    "[, 7]\tqsec\t1/4 mile time\n",
    "[, 8]\tvs\tV/S\n",
    "[, 9]\tam\tTransmission (0 = automatic, 1 = manual)\n",
    "[,10]\tgear\tNumber of forward gears\n",
    "[,11]\tcarb\tNumber of carburetors\n",
    "Source\n",
    "\n",
    "Henderson and Velleman (1981), Building multiple regression models interactively. Biometrics, 37, 391–411.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfcars=pd.read_csv(\"data/mtcars.csv\")\n",
    "dfcars.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 1\n",
    "\n",
    "There is an poorly named column here. Change the \"Unnamed: 0\" column to \"name\".\n",
    "\n",
    "https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.rename.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your work here\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfcars.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 2\n",
    "\n",
    "Parse out the car `maker` from column $0$, i.e., the column you just renamed, and create a new `maker` column with this information. Display the first 10 lines of this new column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your work here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is what the dataframe looks like now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfcars.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 3\n",
    "\n",
    "Construct and display the `avg_mpg` series by using the \"split-apply-combine\" paradigm and summarizing within group data by a mean.\n",
    "\n",
    "https://pandas.pydata.org/pandas-docs/version/0.23.4/groupby.html   \n",
    "\n",
    "Your results should look similar to the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "maker\n",
    "AMC         15.200000\n",
    "Cadillac    10.400000\n",
    "Camaro      13.300000\n",
    "Chrysler    14.700000\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your work here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic  Exploratory Data Analysis (EDA)  \n",
    "\n",
    "Basic objectives for EDA:  \n",
    "\n",
    "1. **Build** a DataFrame from the data (ideally, put all data into this object)\n",
    "2. **Clean** the DataFrame. It should have the following properties:\n",
    "    - Each row describes a single object\n",
    "    - Each column describes a property of that object\n",
    "    - Columns are numeric whenever appropriate\n",
    "    - Columns contain atomic properties that cannot be further decomposed  \n",
    "3. Explore **global properties**. Use histograms, scatter plots, and aggregation functions to summarize the data.\n",
    "4. Explore **group properties**. Use groupby and small multiples to compare subsets of the data.\n",
    "\n",
    "This process transforms your data into a format which is easier to work with, gives you a basic overview of the data's properties, and likely generates several questions for you to followup in subsequent analysis.\n",
    "\n",
    "So far we have **built** the dataframe, and carried out very minimal cleaning (renaming) in this dataframe. \n",
    "\n",
    "### Exploring global properties\n",
    "\n",
    "We are going to focus on visualizing global properties of the data set below. For now, we'll focus on `mpg` to illustrate the concepts, but you should be doing this for all the columns. It may identify interesting properties and even errors in the data.\n",
    "\n",
    "While we do this, we will see several examples of the  `matplotlib` plotting experience.\n",
    "\n",
    "Below, we are setting our matplotlib style to `ggplot`, which is modeled after an R library. The default is 'classic.' Feel free to experiment with other styles:   \n",
    "\n",
    "https://matplotlib.org/users/style_sheets.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bar Charts\n",
    "\n",
    "Matplotlib is accessible via Pandas series. We can use the plot function with $kind=\"barh\"$ to generate very nice horizontal bar charts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_mpg.plot(kind=\"barh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_mpg.plot(kind=\"barh\")\n",
    "plt.show() # we can remove the '<matplotlib.axes...' by adding a function that does not return anything.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Histograms\n",
    "\n",
    "Numerical data leads to distributions, and distributions to histograms. Here is the Pandas default histogram:\n",
    "\n",
    "https://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.hist.html   \n",
    "\n",
    "https://matplotlib.org/api/_as_gen/matplotlib.pyplot.hist.html  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using pandas interface:\n",
    "dfcars.mpg.hist()\n",
    "plt.xlabel(\"mpg\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And matplotlib interface:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(dfcars.mpg.values);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 4\n",
    "\n",
    "Generate a histogram of mpg with 50 bins. Add a vertical line in blue, 75% of the plot height to show the mean mpg.\n",
    "\n",
    "Your plot should look something like the following:  \n",
    "    \n",
    "<img src='hist_with_mean.png' width='500px'>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your owrk here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can add a kernel density estimate (KDE) to our histogram as follows:\n",
    "    \n",
    "https://pandas.pydata.org/pandas-docs/version/0.22/generated/pandas.DataFrame.plot.kde.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "dfcars.mpg.hist(bins=10, density=True, ax=ax)\n",
    "dfcars.mpg.plot.kde(ax=ax, legend=False, title='Car MPG')\n",
    "plt.axvline(dfcars.mpg.mean(), 0, 0.75, color='b', label='Mean')\n",
    "plt.xlabel(\"mpg\");\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting features against other features\n",
    "\n",
    "Sometimes we want to see co-variation amongst our columns. A scatter-plot does this for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(dfcars.wt, dfcars.mpg);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually we use `plt.show()` at the end of every plot to show the plot. The magic function `%matplotlib inline` takes care of this for us, and we dont have to doit in the jupyter notebook. But if you run your puthon program from a file, you will need to explicitly have a call to show. Does not hurt us to include it and it eliminates the object reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(dfcars.wt, dfcars.mpg, marker='o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to save our figure into a file, the `savefig` needs to be in the same cell as the plotting commands. Go look at the files.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(dfcars.wt, dfcars.mpg, 'o', markersize=4, alpha=0.5)\n",
    "plt.savefig('scatter1.png')\n",
    "plt.savefig('scatter2.png', bbox_inches='tight') #less whitespace around image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image('scatter2.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trend\n",
    "\n",
    "The correlation that we saw might suggest a trend. We can capture it with a \"regression\". We'll learn more about regressions soon, but we show a quadratic fit here with a 1 standard deviation bar to show the graphics aspect of this. Also see the Seaborn `sns.regplot`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = dfcars.wt\n",
    "y = dfcars.mpg\n",
    "params = np.polyfit(x, y, 2)\n",
    "xp = np.linspace(x.min(), x.max(), 20)\n",
    "yp = np.polyval(params, xp)\n",
    "plt.plot(xp, yp, 'k', alpha=0.8, linewidth=1)\n",
    "plt.plot(dfcars.wt, dfcars.mpg, 'o', markersize=4, alpha=0.5)\n",
    "sig = np.std(y - np.polyval(params, x))\n",
    "plt.fill_between(xp, yp - sig, yp + sig, \n",
    "                 color='k', alpha=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 5\n",
    "\n",
    "Generate a scatter plot with a regression like the plot above for hp vs. mpg. Use 2 standard deviations. Please feel free to experiment.\n",
    "\n",
    "Note the use of numpy polyfit above to fit a second-order polynomial to the data.\n",
    "\n",
    "https://docs.scipy.org/doc/numpy/reference/generated/numpy.polyfit.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your work here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group Properties\n",
    "\n",
    "\"Co-variational\" plots, and single-variable plots, can be more interesting when we look at them *conditioned* upon the value of a categorical variable.\n",
    "\n",
    "Such conditionality is behind the notion of grouping, where we group our data by various values of categorical variables, for example, whether our cars have an automatic transmission or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping of one outcome variable\n",
    "\n",
    "The notion of grouping based on combinations of factors is used to make various easy-to-see exploratory visualizations for us. \n",
    "\n",
    "First, we make a boxplot of  `mpg`, grouped by transmission style.\n",
    "\n",
    "https://matplotlib.org/api/_as_gen/matplotlib.pyplot.boxplot.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure instance\n",
    "fig = plt.figure(1, figsize=(9, 6))\n",
    "\n",
    "# Create an axes instance\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "# Create the boxplot\n",
    "bp = ax.boxplot(dfcars.mpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 6\n",
    "\n",
    "Create boxplots for all mpg, hp, and disp on a single plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your work here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can see that the difference in mpg is more significant between 6 and 8 cylinder cars, for manual transmissions. And that the large-range effect in automatics is coming almost entirely through 4-cylinder cars.  \n",
    "\n",
    "What about the better mpg for automatics? We can see how representative these are in our sample. We'll show this using a cross-tabulation. Note: We can comine the cross-tab with a graph.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(dfcars.am, dfcars.cyl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 7\n",
    "\n",
    "Examine the dtcar sets. Create a cross tab of two parameters of your choosing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your work here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Faceting for general grouping\n",
    "\n",
    "Seaborn package which is built on matplotlib provides a nice construct: the `FacetGrid`. You decide what variables to facet over, and then decide the kind of plot you want. Here we want hue to be `am`, and  different columns in the  plot grid to be cylinders. We then ask for a facet plot  of `mpg` against `wt` scatter.\n",
    "\n",
    "https://seaborn.pydata.org/generated/seaborn.FacetGrid.html\n",
    "\n",
    "Such plots are often called small multiple plots. They repeat the same plot based on categories, making sure that all plotting parameters are the same so that we have direct comparability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(dfcars, col=\"cyl\", hue=\"am\", palette=\"Set1\")\n",
    "g.map(plt.scatter, \"mpg\", \"wt\", alpha=0.5, s=10);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the \"regression-like\" effect is \"cleanest\" for automatic transmissions in 4 cylinder cars.\n",
    "\n",
    "#### SPLOM, or Scatter Plot Matrix\n",
    "\n",
    "Creating 2-by-2 basis for every pair of continuously co-varying features can get tedious.  The `PairGrid`, colorable by transmission type, allows us to do this comparison for 5 continuous features here, with the diagonal being a kernel density estimate.\n",
    "\n",
    "https://seaborn.pydata.org/generated/seaborn.PairGrid.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.PairGrid(dfcars, vars=['mpg', 'hp', 'wt', 'qsec', 'disp'], hue=\"am\")\n",
    "g.map_diag(sns.kdeplot)\n",
    "g.map_offdiag(plt.scatter, s=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In many places, for example `mpg` vs `disp`, you will see two separate trends for the different transmissions. This suggests the addition of a transmission term as a **indicator** variable in regressions for `mpg` against various features. This changes the intercept of the regression. But the trends have different slopes as well, which suggests that `disp` may interact with `am`, the transmission indicator to create a varying slope as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 8\n",
    "\n",
    "Experiment with sns.PairGrid using coloring for categorical variables other than `am` and see if you can identify any changes in scatter plot pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your work here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation\n",
    "\n",
    "The SPLOM seems to suggest correlations. We can calculate corelation with the Pandas corr() function.\n",
    "\n",
    "https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.corr.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfcars[['mpg', 'wt', 'hp', 'qsec', 'disp']].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since correlations range from -1 to 1 through 0, a diverging palette is usually a good choice for visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpal = sns.choose_colorbrewer_palette('diverging', as_cmap=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use `maptplotlib`s correlation plot. These plots are especially helpful for both EDA and do see misclassification from your machine learning algorithms. EDA is even useful at the analysis stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(dfcars[['mpg', 'wt', 'hp', 'qsec', 'disp']].corr(), cmap=dpal)\n",
    "ax = plt.gca()\n",
    "ax.tick_params(axis='both', which='both',length=0);\n",
    "plt.title(\"Correlation Matrix\")\n",
    "plt.xticks(range(4), ['mpg', 'wt', 'hp', 'qsec', 'disp'])\n",
    "plt.yticks(range(4), ['mpg', 'wt', 'hp', 'qsec', 'disp']);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KDE plots and sequential palettes.\n",
    "\n",
    "We can make a KDE plot of a multivariate normal distribution. Since a probability density is strictly positive, with values near $0$ not being so interesting, a sequential palette is a good approach. Seaborn will by default provide such a palette for KDE plots, but you can also make your own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean, cov = [0, 1], [(1, .5), (.5, 1)]\n",
    "data = np.random.multivariate_normal(mean, cov, 1000)\n",
    "df = pd.DataFrame(data, columns=[\"x\", \"y\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqpal = sns.choose_colorbrewer_palette(\"sequential\", as_cmap=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(df.x, df.y, cmap=seqpal, shade=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matplotlib and multiple plots: Small Multiples\n",
    "\n",
    "There are many cases where we want to see plots side by side. For example, SPLOMS and Facet grids. \n",
    "\n",
    "Here is an example of a plot with one column and 3 rows. \n",
    "\n",
    "https://matplotlib.org/api/_as_gen/matplotlib.pyplot.subplot.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5, 9))\n",
    "\n",
    "ax1 = fig.add_subplot(311)\n",
    "ax1.plot([1, 2, 3], [1, 2, 3])\n",
    "ax1.set_xticklabels([])\n",
    "ax1.set_ylim([1.0, 3.0])\n",
    "\n",
    "ax2 = fig.add_subplot(312)\n",
    "ax2.scatter([1, 2, 3], [1, 2, 3])\n",
    "ax2.set_xticklabels([])\n",
    "ax2.set_ylim([1.0, 3.0])\n",
    "\n",
    "ax3 = fig.add_subplot(313)\n",
    "ax3.plot([1, 2, 3], [1, 2, 3])\n",
    "ax3.set_ylim([1.0, 3.0])\n",
    "\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Small multiples, another approach\n",
    "\n",
    "Here is another approach, which might be more straightforward than using `add_subplot`. It basically creates an array of plots and zips this array up with the various data grouped by categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(12, 12))\n",
    "print(axes)\n",
    "print(axes.ravel())\n",
    "carbs = ['==1', '==2', '==3', '>=4']\n",
    "bins = np.arange(10, 30, 2)\n",
    "for ax, carb in zip(axes.ravel(), carbs):\n",
    "    data = dfcars.query(\"carb%s\" % carb)\n",
    "    print(data.shape)\n",
    "    #ax.plot(data.wt, data.mpg, 'o', markersize=10, alpha=0.5)\n",
    "    ax.hist(data.mpg, bins=bins, histtype='stepfilled', normed=True, color='r', alpha=.3)    \n",
    "    ax.annotate(\"carb\"+str(carb), xy=(12, 0.35), fontsize=14)\n",
    "    #ax.set_yticks([])\n",
    "    ax.set_ylim((0,0.4))\n",
    "    ax.set_xlabel('mpg');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 9\n",
    "\n",
    "Take a few moments and re-examine the orginal dataset. Identify a couple of variables that you believe would be interesting to investigate. Generate subplots for different values for one of the two variables similar to the plot above. multiple plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your work here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 10\n",
    "\n",
    "Create one additional plot you believe would be relevant to understanding the dataset. You may use any combination of variables and plot type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your work here\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
